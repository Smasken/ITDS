{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1\n",
    "\n",
    "This is essentially the same as problem 4 in assignment 1\n",
    "\n",
    "Let‚Äôs say we have an exam question which consists of 20 yes/no questions. From past performance of\n",
    "similar students, a randomly chosen student will know the correct answer to ùëÅ ‚àº binom(20, 11/20)\n",
    "questions. Furthermore, we assume that the student will guess the answer with equal probability\n",
    "to each question they don‚Äôt know the answer to, i.e. given ùëÅ we define ùëç ‚àº binom(20 ‚àí ùëÅ , 1/2) as\n",
    "the number of correctly guessed answers. Define ùëå = ùëÅ + ùëç, i.e., ùëå represents the number of total\n",
    "correct answers.\n",
    "We are interested in setting a deterministic threshold ùëá , i.e., we would pass a student at threshold\n",
    "ùëá if ùëå ‚â• ùëá . Here ùëá ‚àà {0, 1, 2, ... , 20}.\n",
    "1. [5p] For each threshold ùëá , compute the probability that the student knows less than\n",
    "10 correct answers given that the student passed, i.e., ùëÅ < 10. Put the answer in\n",
    "problem11_probabilities as a list.\n",
    "2. [3p] What is the smallest value of ùëá such that if ùëå ‚â• ùëá then we are 90% certain that ùëÅ ‚â• 10?"
   ],
   "id": "31d0e6f3b99e9817"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:02.991076Z",
     "start_time": "2025-01-13T16:45:02.988911Z"
    }
   },
   "source": [
    "# We want to find P(N<10|Y>=T) (A|B)"
   ],
   "id": "61ad5aed391a1df6",
   "outputs": [],
   "execution_count": 495
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.192204Z",
     "start_time": "2025-01-13T16:45:03.015158Z"
    }
   },
   "source": [
    "from scipy.special import binom as binomial\n",
    "from scipy.stats import binom as binomial_pmf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_questions = 20\n",
    "p_know = 11 / 20\n",
    "p_guess = 1 / 2\n",
    "p_N = lambda k: binomial(n_questions, k) * ((1 - p_know) ** (n_questions - k)) * (\n",
    "            (p_know) ** k)  # the PMF of N is p_N(k) where p_N is\n",
    "\n",
    "\n",
    "def prob_Y_given_N(y, k):\n",
    "    return binomial_pmf.pmf(y - k, n_questions - k, p_guess)\n",
    "\n",
    "\n",
    "def prob_Y(y):\n",
    "    return sum(p_N(k) * prob_Y_given_N(y, k) for k in range(n_questions + 1))\n",
    "\n",
    "\n",
    "def prob_Y_geq_T(T):\n",
    "    return sum(prob_Y(y) for y in range(T, n_questions + 1))\n",
    "\n",
    "\n",
    "def prob_N_given_Y(T):\n",
    "    prob = 0\n",
    "    for k in range(5):\n",
    "        for y in range(T, n_questions + 1):\n",
    "            prob += p_N(k) * prob_Y_given_N(y, k)\n",
    "    return prob\n",
    "\n",
    "\n",
    "problem11_probabilities = []\n",
    "\n",
    "for T in range(n_questions + 1):\n",
    "    p_N_given_Y = prob_N_given_Y(T)\n",
    "    p_Y_geq_T = prob_Y_geq_T(T)\n",
    "    if p_Y_geq_T > 0:\n",
    "        cond_prob = p_N_given_Y / p_Y_geq_T\n",
    "    else:\n",
    "        cond_prob = 0\n",
    "    problem11_probabilities.append(cond_prob)\n",
    "\n",
    "problem11_probabilities"
   ],
   "id": "e36a20a65db9db7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0015307441509554297),\n",
       " np.float64(0.0015307441508450256),\n",
       " np.float64(0.0015307441432394124),\n",
       " np.float64(0.0015307438943668445),\n",
       " np.float64(0.0015307387510004125),\n",
       " np.float64(0.0015306634578246326),\n",
       " np.float64(0.0015299831809291856),\n",
       " np.float64(0.001525995482238295),\n",
       " np.float64(0.0015097453994162818),\n",
       " np.float64(0.0014613233766861324),\n",
       " np.float64(0.001352242121684195),\n",
       " np.float64(0.0011625255705667336),\n",
       " np.float64(0.0009042671762339275),\n",
       " np.float64(0.0006257545746121421),\n",
       " np.float64(0.0003838760049282565),\n",
       " np.float64(0.00021057755764174177),\n",
       " np.float64(0.00010495959267083927),\n",
       " np.float64(4.8399893298043265e-05),\n",
       " np.float64(2.0989815106644922e-05),\n",
       " np.float64(8.676066230525746e-06),\n",
       " np.float64(3.4534154491733502e-06)]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 496
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Problem 4",
   "id": "ed2767e499f68d2b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.213247Z",
     "start_time": "2025-01-13T16:45:03.196342Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Don't bother this\n",
    "data_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\n",
    "data_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})\n",
    "data_text = data_raw.iloc[:, 1].str.lower()\n",
    "sms_tuples = list(zip(data_text, data_flag))\n",
    "\n",
    "# PROBABILITY THAT SMS CONTAINS ‚ÄúFREE‚Äù OR ‚ÄúPRIZE‚Äù\n",
    "a = 0\n",
    "for text, bool in sms_tuples:\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        a += 1\n",
    "\n",
    "P_B = a / len(sms_tuples)\n",
    "\n",
    "# PROBABILITY THAT A SMS IS SPAM\n",
    "b = 0\n",
    "for text, bool in sms_tuples:\n",
    "    if bool:\n",
    "        b += 1\n",
    "\n",
    "P_A = b / len(sms_tuples)\n",
    "\n",
    "# PROBABILITY THAT \"FREE\" OR \"PRIZE\" IS SPAM\n",
    "sms_tuples_spam = []\n",
    "for text, bool in sms_tuples:\n",
    "    if bool:\n",
    "        sms_tuples_spam.append((text, bool))\n",
    "\n",
    "k = 0\n",
    "for text, bool in sms_tuples_spam:\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        k += 1\n",
    "\n",
    "P_BA = k / len(sms_tuples_spam)\n",
    "\n",
    "# PROBABILITY THAT IT IS SPAM IF CONTAINS \"FREE\" OR \"PRIZE\"\n",
    "P_AB = (P_BA * P_A) / P_B\n",
    "print(P_AB)\n",
    "\n",
    "'''\n",
    "# ALTERNATIV L√ñSNING (KORT)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\n",
    "data_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})  # 0 = ham, 1 = spam\n",
    "data_text = data_raw.iloc[:, 1].str.lower()  # Convert to lowercase\n",
    "sms_tuples = list(zip(data_text, data_flag))\n",
    "\n",
    "# Filter SMS messages containing \"free\" or \"prize\"\n",
    "filtered_sms = [(text, label) for text, label in sms_tuples if \"free\" in text or \"prize\" in text]\n",
    "\n",
    "# Extract labels (1 = spam, 0 = ham) for filtered SMS\n",
    "spam_labels = [label for text, label in filtered_sms]\n",
    "\n",
    "# Calculate P(Y=1 | \"free\" or \"prize\")\n",
    "P_AB = sum(spam_labels) / len(spam_labels)\n",
    "print(f\"P(Y=1 | 'free' or 'prize' in SMS): {P_AB}\")\n",
    "'''\n"
   ],
   "id": "3fe48d279f6e19b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808695652173913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# ALTERNATIV L√ñSNING (KORT)\\n\\nimport pandas as pd\\n\\n# Load data\\ndata_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\\ndata_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})  # 0 = ham, 1 = spam\\ndata_text = data_raw.iloc[:, 1].str.lower()  # Convert to lowercase\\nsms_tuples = list(zip(data_text, data_flag))\\n\\n# Filter SMS messages containing \"free\" or \"prize\"\\nfiltered_sms = [(text, label) for text, label in sms_tuples if \"free\" in text or \"prize\" in text]\\n\\n# Extract labels (1 = spam, 0 = ham) for filtered SMS\\nspam_labels = [label for text, label in filtered_sms]\\n\\n# Calculate P(Y=1 | \"free\" or \"prize\")\\nP_AB = sum(spam_labels) / len(spam_labels)\\nprint(f\"P(Y=1 | \\'free\\' or \\'prize\\' in SMS): {P_AB}\")\\n'"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 497
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.233508Z",
     "start_time": "2025-01-13T16:45:03.228517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def hoeffdings_range_based(X, alpha):\n",
    "    log_term = np.log(2 / (1 - alpha))\n",
    "    range_term = (np.max(X) - np.min(X)) ** 2\n",
    "    denominator = 2 * len(X)\n",
    "\n",
    "    epsilon = np.sqrt((log_term * range_term) / denominator)\n",
    "    sample_mean = np.mean(X)\n",
    "\n",
    "    return sample_mean - epsilon, sample_mean + epsilon\n",
    "\n",
    "\n",
    "gg = []\n",
    "for text, bool in sms_tuples:\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        gg.append((text, bool))\n",
    "\n",
    "spam_list = []\n",
    "for text, bool in gg:\n",
    "    spam_list.append(bool)\n",
    "\n",
    "print(hoeffdings_range_based(spam_list, 0.9))\n",
    "\n"
   ],
   "id": "94e93c8ffd415189",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(0.7428045224509738), np.float64(0.8745867818968522))\n"
     ]
    }
   ],
   "execution_count": 498
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.274049Z",
     "start_time": "2025-01-13T16:45:03.258137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\n",
    "data_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})  # 0 = ham, 1 = spam\n",
    "data_text = data_raw.iloc[:, 1].str.lower()  # Convert to lowercase\n",
    "sms_tuples = list(zip(data_text, data_flag))\n",
    "\n",
    "# Filter SMS messages containing \"free\" or \"prize\"\n",
    "filtr_sms = []\n",
    "for text, bool in sms_tuples:\n",
    "    if text.count(\"free\") == 2:\n",
    "        filtr_sms.append((text, bool))\n",
    "\n",
    "spm_labels = []\n",
    "for text, bool in filtr_sms:\n",
    "    spm_labels.append(bool)\n",
    "\n",
    "# Calculate P(Y=1 | \"free\" or \"prize\")\n",
    "P_AB = sum(spm_labels) / len(spm_labels)\n",
    "print(f\"P(Y=1 | 'free' or 'prize' in SMS): {P_AB}\")\n",
    "\n",
    "ff = []\n",
    "for text, bool in sms_tuples:\n",
    "    if text.count(\"free\") == 2:\n",
    "        ff.append((text, bool))\n",
    "\n",
    "schozz = []\n",
    "for text, bool in ff:\n",
    "    schozz.append(bool)\n",
    "\n",
    "print(hoeffdings_range_based(schozz, 0.9))"
   ],
   "id": "d271ecc8e4341728",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y=1 | 'free' or 'prize' in SMS): 0.9736842105263158\n",
      "(np.float64(0.7751457258056348), np.float64(1.172222695246997))\n"
     ]
    }
   ],
   "execution_count": 499
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.278767Z",
     "start_time": "2025-01-13T16:45:03.277315Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2eeb55d98d679aeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Problem 5**",
   "id": "afb52ff5880d9723"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.715601Z",
     "start_time": "2025-01-13T16:45:03.295784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data_2/flights.csv\")\n",
    "unique_cities = np.unique(data[[\"from\", \"to\"]])\n",
    "unique_userCodes = np.unique(data[\"userCode\"])\n",
    "\n",
    "number_of_cities = len(unique_cities)\n",
    "number_of_userCodes = len(unique_userCodes)\n",
    "number_of_observations = 271887\n"
   ],
   "id": "a76576fd55a661c0",
   "outputs": [],
   "execution_count": 500
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.732489Z",
     "start_time": "2025-01-13T16:45:03.730073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "    Param myDataList, a list of data.\n",
    "    Return a dictionary mapping each unique data value to its frequency count.\n",
    "    '''\n",
    "    freqDict = {}  # start with an empty dictionary\n",
    "    for res in myDataList:\n",
    "        if res in freqDict:  # the data value already exists as a key\n",
    "            freqDict[res] = freqDict[res] + 1  # add 1 to the count using sage integers\n",
    "        else:  # the data value does not exist as a key value\n",
    "            freqDict[res] = 1  # add a new key-value pair for this new data value, frequency 1\n",
    "    return (freqDict)  # return the dictionary created"
   ],
   "id": "bd548259779deb17",
   "outputs": [],
   "execution_count": 501
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.815013Z",
     "start_time": "2025-01-13T16:45:03.745800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cities = XXX\n",
    "unique_cities = sorted(unique_cities) # The unique cities\n",
    "n_cities = len(unique_cities) # The number of unique citites\n",
    "\n",
    "# Count the different transitions\n",
    "transitions = zip(data[\"from\"], data[\"to\"]) # A list containing tuples ex: ('Aracaju (SE)','Rio de Janeiro (RJ)') of all transitions in the text\n",
    "\n",
    "transition_counts = makeFreqDict(transitions) # A dictionary that counts the number of each ransition\n",
    "# ex: ('Aracaju (SE)','Rio de Janeiro (RJ)'):4\n",
    "\n",
    "indexToCity = {i: city for i, city in enumerate(unique_cities)} # A dictionary that maps the n-1 number to the n:th unique_city,\n",
    "# ex: 0:'Aracaju (SE)'\n",
    "cityToIndex = {city: i for i, city in enumerate(unique_cities)} # The inverse,\n",
    "# ex: 'Aracaju (SE)':0\n",
    "\n",
    "# Part 3, finding the maximum likelihood estimate of the transition matrix\n",
    "\n",
    "transition_matrix = np.zeros((n_cities, n_cities)) # a numpy array of size (n_cities,n_cities)\n",
    "\n",
    "for (city_from, city_to), freq in transition_counts.items():\n",
    "    transition_matrix[cityToIndex[city_from], cityToIndex[city_to]] = freq\n",
    "\n",
    "\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# The transition matrix should be ordered in such a way that\n",
    "# p_{'Aracaju (SE)','Rio de Janeiro (RJ)'} = transition_matrix[cityToIndex['Aracaju (SE)'],cityToIndex['Rio de Janeiro (RJ)']]\n",
    "# and represents the probability of travelling Aracaju (SE)->Rio de Janeiro (RJ)\n"
   ],
   "id": "9ecff9a513c32118",
   "outputs": [],
   "execution_count": 502
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.831120Z",
     "start_time": "2025-01-13T16:45:03.828515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stat_distr(p):\n",
    "    A = p.T - np.eye(p.shape[0])\n",
    "    b = np.zeros(p.shape[0])\n",
    "\n",
    "    A[-1] = 1\n",
    "    b[-1] = 1\n",
    "\n",
    "    return np.linalg.solve(A, b)\n",
    "\n",
    "print(stat_distr(transition_matrix))\n"
   ],
   "id": "5aada97cb1f04fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13690932 0.1132047  0.12780262 0.21081107 0.08752133 0.11210498\n",
      " 0.06184532 0.06290826 0.0868924 ]\n"
     ]
    }
   ],
   "execution_count": 503
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.846920Z",
     "start_time": "2025-01-13T16:45:03.844429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_pos = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "three_steps = np.linalg.matrix_power(transition_matrix, 3)\n",
    "final_pos = start_pos @ three_steps\n",
    "\n",
    "print(final_pos[0])"
   ],
   "id": "45a32b629f4b17b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13331717737273135\n"
     ]
    }
   ],
   "execution_count": 504
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.861899Z",
     "start_time": "2025-01-13T16:45:03.860222Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c0bcc3f89f7af134",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Problem 6**",
   "id": "459c6e3310ad5eed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.948629Z",
     "start_time": "2025-01-13T16:45:03.876962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = data_text\n",
    "Y = data_flag\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.2)\n",
    "\n",
    "pipeline = Pipeline([(\"Vectorizer\", CountVectorizer()), (\"Classifier\", LogisticRegression(solver=\"liblinear\"))])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test, pred, output_dict=True)\n",
    "tn, fp, fn, tp = classification_report(Y_test, pred, output_dict=True)\n",
    "\n",
    "print(report)\n",
    "\n",
    "\n",
    "def hoeffdings_range_based(X, alpha):\n",
    "\n",
    "    log_term = np.log(2 / (1 - alpha))\n",
    "    range_term = (np.max(X) - np.min(X)) ** 2\n",
    "    denominator = 2 * len(X)\n",
    "\n",
    "    epsilon = np.sqrt((log_term * range_term) / denominator)\n",
    "    sample_mean = np.mean(X)\n",
    "\n",
    "    return sample_mean - epsilon, sample_mean + epsilon\n",
    "\n",
    "print(hoeffdings_range_based(pipeline.predict(X_test), 0.95))\n"
   ],
   "id": "335dbce5b5162530",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9757085020242915, 'recall': 0.9989637305699481, 'f1-score': 0.9871991807475679, 'support': 965.0}, '1': {'precision': 0.9921259842519685, 'recall': 0.84, 'f1-score': 0.9097472924187726, 'support': 150.0}, 'accuracy': 0.9775784753363229, 'macro avg': {'precision': 0.98391724313813, 'recall': 0.9194818652849741, 'f1-score': 0.9484732365831703, 'support': 1115.0}, 'weighted avg': {'precision': 0.9779171319203914, 'recall': 0.9775784753363229, 'f1-score': 0.9767796442010932, 'support': 1115.0}}\n",
      "(np.float64(0.0956303352101106), np.float64(0.13217235537284905))\n"
     ]
    }
   ],
   "execution_count": 505
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
